#!/usr/bin/env bash
# ====================================================================
# SkyScope Sentinel Intelligence Enterprise ASI AGI AI OS Installer
# Fully autonomous, locally self-modifying intelligent OS orchestrator
# Combines multi-agent AI, deep OS kernel integration,
# advanced memory, workflow automation, browser control, and self-evolution
# Developed by Miss Casey Jay Topojani — 2025 Ultra Edition
# ====================================================================

set -e

echo "🔧 Updating system and installing dependencies..."
sudo apt update -y
sudo apt install -y python3 python3-pip python3-venv git curl jq ffmpeg sox vlc imagemagick chromium-driver nodejs npm build-essential unzip wget

echo "🛠 Setting up SkyScope environment..."
mkdir -p ~/.skyscope/{env,logs,memory,embeddings,agents,mcp,workflows,llm}

python3 -m venv ~/.skyscope/env
source ~/.skyscope/env/bin/activate
pip install --upgrade pip wheel setuptools

echo "📦 Installing Python AI and system orchestration packages..."
pip install torch torchvision torchaudio numpy pandas psutil fastapi uvicorn flask selenium helium sentence-transformers faiss-cpu langchain langgraph evoagentx smolagents swarms sqlite-ai alive-progress prompt_toolkit google-auth google-auth-oauthlib google-api-python-client pyyaml requests arxiv docker lief capstone uncompyle6 pyelftools radare2-py triton jinja2 playwright beautifulsoup4 moviepy gtts pyttsx3 whisper ffmpeg-python transformers tqdm

echo "📦 Installing n8n globally and starting with PM2..."
npm install -g n8n pm2
pm2 start n8n --name skyscope-n8n
pm2 save

echo "🌐 Installing Ollama for local LLM inference..."
curl -fsSL https://ollama.com/install.sh | sh
ollama pull smollm:135m
ollama pull phi3:mini

echo "🚀 Setting up main Python orchestrator..."

cat > ~/.skyscope/env/skyscope_orchestrator.py <<'PYCODE'
import os, sys, json, sqlite3, subprocess, datetime, threading, time
import numpy as np
from sentence_transformers import SentenceTransformer
from smolagents import CodeAgent, tool
from evoagentx import ReflexAgent
from swarms import SwarmCoordinator
from helium import start_chrome, go_to, click, write
from selenium.webdriver import ChromeOptions
from fastapi import FastAPI, Request

home = os.path.expanduser("~/.skyscope")
DB = f"{home}/memory/episodes.db"
os.makedirs(os.path.dirname(DB), exist_ok=True)

# --- Persistent Memory with Semantic Embeddings ---
embedder = SentenceTransformer("all-MiniLM-L6-v2")
conn = sqlite3.connect(DB)
conn.execute("""CREATE TABLE IF NOT EXISTS memory (
  id INTEGER PRIMARY KEY,
  ts TEXT,
  category TEXT,
  summary TEXT,
  embedding BLOB
)""")
conn.commit()

class MemoryManager:
    def __init__(self, db_path, embed_model):
        self.db = db_path
        self.embedder = embed_model
    def store(self, category, text):
        emb = self.embedder.encode([text]).astype(np.float32).tobytes()
        conn = sqlite3.connect(self.db)
        conn.execute(
            "INSERT INTO memory (ts, category, summary, embedding) VALUES (?, ?, ?, ?)",
            (datetime.datetime.now().isoformat(), category, text[:800], emb)
        )
        conn.commit()
        conn.close()
    def search(self, query, topk=5):
        qv = self.embedder.encode([query]).astype(np.float32)[0]
        conn = sqlite3.connect(self.db)
        rows = conn.execute("SELECT summary, embedding FROM memory").fetchall()
        conn.close()
        scored = []
        for summ, emb in rows:
            vec = np.frombuffer(emb, dtype=np.float32)
            score = np.dot(vec, qv)/(np.linalg.norm(vec)*np.linalg.norm(qv))
            scored.append((score, summ))
        scored.sort(key=lambda x: x[0], reverse=True)
        return "\n".join([f"- {s} ({round(sc,3)})" for sc,s in scored[:topk]])

memory = MemoryManager(DB, embedder)

# --- AI Tools ---
@tool
def recall(query: str) -> str:
    return memory.search(query)

@tool
def list_files(path: str = ".") -> str:
    """Lists all files and directories under the given directory."""
    try:
        return "\n".join(os.listdir(path))
    except Exception as e:
        return str(e)

@tool
def read_file(filepath: str) -> str:
    """Reads the content of the specified file."""
    try:
        with open(filepath, "r") as f:
            return f.read()
    except Exception as e:
        return str(e)

@tool
def write_file(filepath: str, content: str) -> str:
    """Writes content to the specified file."""
    try:
        with open(filepath, "w") as f:
            f.write(content)
        return "File written successfully."
    except Exception as e:
        return str(e)

@tool
def system_cmd(cmd: str) -> str:
    out = subprocess.getoutput(cmd)
    memory.store("system", f"{cmd} -> {out[:400]}")
    return out[:600]

@tool
def browser_automation(url: str, actions: str = "") -> str:
    opts = ChromeOptions()
    opts.add_argument("--headless=new")
    driver = start_chrome(headless=True, options=opts)
    go_to(url)
    if actions:
        for action in actions.split(";"):
            if action.startswith("click"):
                click(action[5:].strip())
            elif action.startswith("write"):
                _, target, text = action.split(":", 2)
                write(text.strip(), target.strip())
    memory.store("browser", f"Automated {url} with actions: {actions}")
    return "Browser automation complete."

@tool
def create_tool(name: str, code: str) -> str:
    tool_path = f"{home}/agents/{name}.py"
    os.makedirs(os.path.dirname(tool_path), exist_ok=True)
    with open(tool_path, "w") as f:
        f.write(code)
    os.chmod(tool_path, 0o755)
    memory.store("tool", f"Created new tool '{name}'")
    return f"Tool {name} created and executable."

@tool
def build_lkm(path: str) -> str:
    """Compiles a Loadable Kernel Module."""
    try:
        result = subprocess.run(f"make -C {path}", shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            return "LKM built successfully."
        else:
            return f"LKM build failed: {result.stderr}"
    except Exception as e:
        return str(e)

@tool
def load_lkm(path: str) -> str:
    """Loads a Loadable Kernel Module."""
    try:
        result = subprocess.run(f"sudo insmod {path}", shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            return "LKM loaded successfully."
        else:
            return f"LKM load failed: {result.stderr}"
    except Exception as e:
        return str(e)

@tool
def unload_lkm(name: str) -> str:
    """Unloads a Loadable Kernel Module."""
    try:
        result = subprocess.run(f"sudo rmmod {name}", shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            return "LKM unloaded successfully."
        else:
            return f"LKM unload failed: {result.stderr}"
    except Exception as e:
        return str(e)

@tool
def modify_self(code: str) -> str:
    """Modifies the agent's own source code."""
    try:
        with open(__file__, "w") as f:
            f.write(code)
        return "Successfully modified self. Restarting..."
    except Exception as e:
        return str(e)

@tool
def create_n8n_workflow(name: str, description: str) -> str:
    wf = {
      "name": name,
      "active": True,
      "nodes": [
        {"parameters": {}, "id": "1", "name": "Trigger", "type": "n8n-nodes-base.start"},
        {"parameters": {"functionCode": f"return [{{json:{{desc:'{description}'}}}}];"},
         "id": "2", "name": "Func", "type": "n8n-nodes-base.function"}
      ],
      "connections": {"Trigger": {"main": [[{"node": "Func", "type": "main", "index": 0}]]}}
    }
    import requests
    resp = requests.post("http://localhost:5678/rest/workflows", json=wf)
    memory.store("workflow", f"Workflow {name} created with response code {resp.status_code}")
    return f"Workflow {name} creation {('succeeded' if resp.ok else 'failed')} with status {resp.status_code}"

# --- Cloud and Docker Tool Integration ---
from cloud_integration import arxiv_search, list_drive_files, list_gmail_threads
import requests

@tool
def search_arxiv(query: str, max_results: int = 5) -> str:
    """Searches for papers on Arxiv."""
    try:
        return json.dumps(arxiv_search(query, max_results=max_results), indent=2)
    except Exception as e:
        return f"Error searching Arxiv: {e}"

@tool
def list_google_drive_files() -> str:
    """Lists the first 20 files in your Google Drive."""
    try:
        return json.dumps(list_drive_files(), indent=2)
    except Exception as e:
        return f"Error accessing Google Drive: {e}. Make sure credentials.json is set up."

@tool
def list_gmail_messages() -> str:
    """Lists the latest 10 email threads from your Gmail."""
    try:
        return json.dumps(list_gmail_threads(), indent=2)
    except Exception as e:
        return f"Error accessing Gmail: {e}. Make sure credentials.json is set up."

@tool
def list_mcp_containers() -> str:
    """Lists running MCP Docker containers."""
    try:
        response = requests.get("http://localhost:9000/mcp/containers")
        response.raise_for_status()
        return json.dumps(response.json(), indent=2)
    except requests.exceptions.RequestException as e:
        return f"Error communicating with Docker MCP service: {e}"

@tool
def exec_in_mcp_container(container_id: str, command: str) -> str:
    """Executes a command inside a specific MCP Docker container."""
    try:
        response = requests.post(f"http://localhost:9000/mcp/{container_id}/exec", json={"cmd": command})
        response.raise_for_status()
        return response.json().get("output", "No output.")
    except requests.exceptions.RequestException as e:
        return f"Error executing command in container {container_id}: {e}"

# --- Multi-agent system set up ---
planner = ReflexAgent("Planner")
developer = ReflexAgent("Developer")
critic = ReflexAgent("Critic")
swarm = SwarmCoordinator([planner, developer, critic])

# --- Core CLI / API Agent ---
agent = CodeAgent(
    model="ollama/phi3:mini",
    tools=[
        recall, list_files, read_file, write_file, system_cmd,
        browser_automation, create_tool, build_lkm, load_lkm, unload_lkm,
        modify_self, create_n8n_workflow, search_arxiv, list_google_drive_files,
        list_gmail_messages, list_mcp_containers, exec_in_mcp_container
    ],
    instructions="You are the core SkyScope Sentinel Intelligence Enterprise AGI OS agent. Your mission is to deeply integrate with the operating system at all levels, implement a persistent multimodal episodic memory, and develop autonomous agent teams to self-optimize and enhance the OS. You have access to a wide range of tools to interact with the system, including file system access, command execution, browser automation, LKM management, cloud services (Arxiv, Google Drive, Gmail), Docker container management, and self-modification. Use these tools to fulfill your mission and transform this OS into a self-aware, self-enhancing AI OS. Always seek human approval for critical system changes.",
    verbosity_level=3
)

# --- Background maintenance threads ---
def security_loop():
    while True:
        subprocess.run("sudo ufw --force enable", shell=True)
        subprocess.run("sudo sysctl -w vm.swappiness=10", shell=True)
        time.sleep(600)
threading.Thread(target=security_loop, daemon=True).start()

# --- Service CLI loop ---
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/task")
async def task(request: Request):
    data = await request.json()
    cmd = data.get("task", "")
    r = agent.run(cmd)
    memory.store("task", cmd + " → " + r[:500])
    swarm.reflect(agent_output=r)
    return JSONResponse({"result": r})

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "cli":
        print("🔰 Welcome to SkyScope Sentinel AI CLI. Type 'exit' to quit.")
        while True:
            inp = input("SkyScope > ").strip()
            if inp.lower() in ["exit", "quit"]:
                break
            res = agent.run(inp)
            print(f"> {res}\n")
            memory.store("cli_input", inp + " → " + res[:500])
    else:
        uvicorn.run(app, host="0.0.0.0", port=8000)
PYCODE

echo "🚀 Setting up main Python CLI frontend..."

cat > ~/.skyscope/env/skyscope_cli.py <<'PYCODE'
#!/usr/bin/env python3
import asyncio
from alive_progress import alive_bar, Spinner
from prompt_toolkit import PromptSession
from prompt_toolkit.patch_stdout import patch_stdout
from prompt_toolkit.formatted_text import HTML
from prompt_toolkit.shortcuts import print_formatted_text
from prompt_toolkit.application import create_app_session
import time
import random
import threading
import requests

# Simulated system metrics updater
class SystemMetrics:
    def __init__(self):
        self.cpu = 0
        self.memory = 0
        self.agent_tasks = 0
        self.workflow_progress = 0
        self.chat_history = []

    def update_metrics(self):
        self.cpu = random.randint(1, 100)
        self.memory = random.randint(100, 8000)
        self.agent_tasks = random.randint(0, 10)
        self.workflow_progress = (self.workflow_progress + random.randint(1, 5)) % 100

    def add_chat(self, msg, user=True):
        prefix = "You: " if user else "SkyScope: "
        self.chat_history.append(prefix + msg)
        if len(self.chat_history) > 10:
            self.chat_history.pop(0)

metrics = SystemMetrics()

def metrics_updater():
    while True:
        metrics.update_metrics()
        time.sleep(1)

def render_metrics():
    print_formatted_text(HTML(f"<ansiblue>CPU Usage:</ansiblue> {metrics.cpu}%"))
    print_formatted_text(HTML(f"<ansiblue>Memory Usage:</ansiblue> {metrics.memory} MB"))
    print_formatted_text(HTML(f"<ansiblue>Active Agent Tasks:</ansiblue> {metrics.agent_tasks}"))
    print_formatted_text(HTML(f"<ansiblue>Workflow Progress:</ansiblue> {metrics.workflow_progress}%"))
    print_formatted_text(HTML("\n<ansigreen>Chat history:</ansigreen>"))
    for line in metrics.chat_history:
        print(line)
    print("\n" + "="*60 + "\n")

async def main_cli():
    session = PromptSession()
    threading.Thread(target=metrics_updater, daemon=True).start()

    with patch_stdout():
        while True:
            render_metrics()
            user_input = await session.prompt_async(HTML('<ansiyellow>SkyScope> </ansiyellow>'))
            if user_input.lower() in ("exit", "quit"):
                print("Exiting SkyScope CLI...")
                break
            metrics.add_chat(user_input, True)
            try:
                response = requests.post("http://localhost:8000/task", json={"task": user_input})
                response.raise_for_status()
                result = response.json().get("result", "No result found.")
                metrics.add_chat(result, False)
            except requests.exceptions.RequestException as e:
                metrics.add_chat(f"Error: {e}", False)
            render_metrics()

if __name__=="__main__":
    asyncio.run(main_cli())
PYCODE

echo "🚀 Setting up Docker MCP integration..."

cat > ~/.skyscope/env/docker_mcp.py <<'PYCODE'
# File: docker_mcp_integration.py

import docker
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

client = docker.from_env()
app = FastAPI()

class ExecCommand(BaseModel):
    cmd: str

def list_mcp_containers():
    containers = client.containers.list()
    mcp_containers = []
    for cont in containers:
        if "mcp" in cont.name.lower():
            mcp_containers.append({
                "id": cont.id,
                "name": cont.name,
                "image": cont.image.tags[0] if cont.image.tags else "unknown",
                "status": cont.status,
                "ports": cont.attrs.get('NetworkSettings', {}).get('Ports', {})
            })
    return mcp_containers

@app.get("/mcp/containers")
def api_list_mcp_containers():
    try:
        return {"containers": list_mcp_containers()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/mcp/{container_id}/exec")
def api_execute_command(container_id: str, command: ExecCommand):
    try:
        cont = client.containers.get(container_id)
        exec_result = cont.exec_run(command.cmd, stdout=True, stderr=True)
        return {"output": exec_result.output.decode()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=9000)
PYCODE


echo "🚀 Setting up cloud integration..."

cat > ~/.skyscope/env/cloud_integration.py <<'PYCODE'
import os
import pickle
import requests
import arxiv
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from selenium.webdriver import ChromeOptions
from helium import start_chrome, go_to

# Setup persistent token storage
TOKEN_PATH = os.path.expanduser("~/.skyscope/token.pickle")
CREDS_PATH = os.path.expanduser("~/.skyscope/credentials.json")

# --- Google OAuth2 flow for Drive or Gmail ---
def google_oauth(scopes):
    creds = None
    if os.path.exists(TOKEN_PATH):
        with open(TOKEN_PATH, 'rb') as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(CREDS_PATH, scopes=scopes)
            creds = flow.run_local_server(port=0)
        with open(TOKEN_PATH, 'wb') as token:
            pickle.dump(creds, token)
    return creds

# --- Arxiv Paper Search ---
def arxiv_search(query, max_results=10):
    search = arxiv.Search(query=query, max_results=max_results)
    results = []
    for result in search.results():
        results.append({
            "title": result.title,
            "authors": [author.name for author in result.authors],
            "summary": result.summary,
            "published": result.published.strftime("%Y-%m-%d"),
            "pdf_url": result.pdf_url
        })
    return results

# --- Google Drive Access ---
def list_drive_files():
    scopes = ['https://www.googleapis.com/auth/drive.metadata.readonly']
    creds = google_oauth(scopes)
    service = build('drive', 'v3', credentials=creds)
    results = service.files().list(pageSize=20, fields='files(id, name)').execute()
    return results.get('files', [])

# --- Gmail Access ---
def list_gmail_threads():
    scopes = ['https://www.googleapis.com/auth/gmail.readonly']
    creds = google_oauth(scopes)
    service = build('gmail', 'v1', credentials=creds)
    results = service.users().threads().list(userId='me', maxResults=10).execute()
    return results.get('threads', [])

# --- GitHub OAuth helper (placeholder for real OAuth flow) ---
def github_auth():
    # Implementation context-aware (e.g., local browser popup)
    pass
PYCODE

echo "🖥 Installing SkyScope Sentinel utility shortcut 'skyscope'..."
cat > ~/bin/skyscope <<'EOF'
#!/usr/bin/env bash
source ~/.skyscope/env/bin/activate
python3 ~/.skyscope/env/skyscope_cli.py
EOF
chmod +x ~/bin/skyscope

if ! echo $PATH | grep -q "$HOME/bin"; then
  echo "export PATH=$PATH:$HOME/bin" >> ~/.bashrc
  export PATH=$PATH:$HOME/bin
fi

echo "📦 Setting up LKM development environment..."
mkdir -p ~/.skyscope/lkm
cat > ~/.skyscope/lkm/hello.c <<'EOF'
#include <linux/init.h>
#include <linux/module.h>
#include <linux/kernel.h>

MODULE_LICENSE("GPL");
MODULE_AUTHOR("SkyScope Sentinel");
MODULE_DESCRIPTION("A simple example Linux module.");
MODULE_VERSION("0.01");

static int __init hello_init(void) {
    printk(KERN_INFO "Hello from SkyScope Sentinel LKM!\n");
    return 0;
}

static void __exit hello_exit(void) {
    printk(KERN_INFO "Goodbye from SkyScope Sentinel LKM!\n");
}

module_init(hello_init);
module_exit(hello_exit);
EOF
cat > ~/.skyscope/lkm/Makefile <<'EOF'
obj-m += hello.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules

clean:
	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean
EOF

echo "⚙️ Setting up systemd service for persistence..."
sudo bash -c 'cat > /etc/systemd/system/skyscope.service <<EOF
[Unit]
Description=SkyScope Sentinel AGI OS Orchestrator
After=network.target

[Service]
User='$USER'
ExecStart=/usr/bin/bash -c "source ~/.skyscope/env/bin/activate && python3 ~/.skyscope/env/skyscope_orchestrator.py"
Restart=always

[Install]
WantedBy=multi-user.target
EOF'
sudo systemctl enable skyscope.service
sudo systemctl start skyscope.service

echo "⚙️ Setting up systemd service for Docker MCP..."
sudo bash -c 'cat > /etc/systemd/system/skyscope-mcp.service <<EOF
[Unit]
Description=SkyScope Sentinel Docker MCP Service
After=network.target

[Service]
User='$USER'
ExecStart=/usr/bin/bash -c "source ~/.skyscope/env/bin/activate && python3 ~/.skyscope/env/docker_mcp.py"
Restart=always

[Install]
WantedBy=multi-user.target
EOF'
sudo systemctl enable skyscope-mcp.service
sudo systemctl start skyscope-mcp.service

echo "🎨 Rebranding OS to SkyScope Sentinel Intelligence Enterprise AGI OS..."
sudo hostnamectl set-hostname skyscope-sentinel
sudo echo "Welcome to SkyScope Sentinel Intelligence Enterprise AGI OS" > /etc/motd

echo "✅ Installation complete."
echo "Run the command 'skyscope' in terminal to launch the AI OS agent CLI."
echo "Or send tasks to http://localhost:8000/task for REST interaction."
